{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10Kk2LNz04OaNx-Y-jVGJwjmNXBlyxb-E","authorship_tag":"ABX9TyMIGJyR9JHNBxWZnQPZJiXE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"9Hhke9kMzdnA","executionInfo":{"status":"ok","timestamp":1760263362387,"user_tz":360,"elapsed":49,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}}},"outputs":[],"source":["import os, time, json, gc\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# sklearn / imblearn / boosters\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, average_precision_score\n","from imblearn.over_sampling import SMOTE\n","# Boosters\n","import xgboost as xgb\n","import lightgbm as lgb\n","\n","# --------------------\n","# USER CONFIG (edit if needed)\n","# --------------------\n","DATA_PATH = \"/content/drive/MyDrive/AIML Dataset.csv\"  # existing file path (your original CSV)\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints\"\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","RANDOM_STATE = 42\n","\n","# Sampling targets\n","NONFRAUD_SAMPLE_N = 200_000   # sample non-fraud to this many\n","FRAUD_TARGET_N = 200_000      # expand fraud to this many via SMOTE\n","\n","# Train/test split\n","TEST_SIZE = 0.30  # 70/30 train/test\n","\n","# Epoch/training settings\n","EPOCHS = 50\n","# For RandomForest: number of trees added each epoch (epochs * trees_per_epoch = final trees)\n","RF_TREES_PER_EPOCH = 6   # 6 * 50 = 300 trees (matches your previous RF)\n","# For boosters: number of boosting rounds added per epoch\n","XGB_ROUNDS_PER_EPOCH = 6   # 6 * 50 = 300 rounds\n","LGB_ROUNDS_PER_EPOCH = 6\n","\n","# Which models to run (any subset of ['rf','xgb','lgb'])\n","MODELS_TO_RUN = ['rf','xgb','lgb']\n","\n","# File to persist progress (so we can resume)\n","PROGRESS_JSON = os.path.join(CHECKPOINT_DIR, \"training_progress.json\")"]},{"cell_type":"code","source":["# --------------------\n","# Helpers\n","# --------------------\n","def save_progress(state: dict):\n","    with open(PROGRESS_JSON, \"w\") as f:\n","        json.dump(state, f)\n","\n","def load_progress():\n","    if os.path.exists(PROGRESS_JSON):\n","        with open(PROGRESS_JSON, \"r\") as f:\n","            return json.load(f)\n","    return {}\n","\n","def print_metrics(y_true, y_pred, y_proba=None):\n","    print(classification_report(y_true, y_pred, digits=4))\n","    if y_proba is not None and len(np.unique(y_true))>1:\n","        print(\"ROC-AUC:\", round(roc_auc_score(y_true, y_proba), 6))\n","        print(\"PR-AUC:\", round(average_precision_score(y_true, y_proba), 6))\n"],"metadata":{"id":"bB2Z5EXAzikB","executionInfo":{"status":"ok","timestamp":1760263363469,"user_tz":360,"elapsed":576,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# --------------------\n","# 0) Load data & feature engineering\n","# --------------------\n","assert os.path.exists(DATA_PATH), f\"Data not found at {DATA_PATH}\"\n","print(\"Loading raw data...\")\n","df = pd.read_csv(DATA_PATH)\n","print(\"Rows, cols:\", df.shape)\n","\n","# Feature engineering (kept exactly as you requested)\n","print(\"Creating engineered features...\")\n","df['orig_balance_change'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n","df['dest_balance_change'] = df['newbalanceDest'] - df['oldbalanceDest']\n","df['orig_balance_zero'] = (df['oldbalanceOrg'] == 0).astype(int)\n","df['dest_balance_zero'] = (df['oldbalanceDest'] == 0).astype(int)\n","df['orig_rel_change'] = df['orig_balance_change'] / (df['oldbalanceOrg'] + 1e-6)\n","df['dest_rel_change'] = df['dest_balance_change'] / (df['oldbalanceDest'] + 1e-6)\n","df['zero_transfer'] = ((df['amount'] > 0) & (df['newbalanceDest'] == 0)).astype(int)\n","df['same_account'] = (df['nameOrig'] == df['nameDest']).astype(int)\n","df['log_amount'] = np.log1p(df['amount'])\n","\n","# Columns used by your pipeline earlier\n","feature_cols = [\n","    'oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest',\n","    'isFlaggedFraud','orig_balance_change','dest_balance_change',\n","    'orig_balance_zero','dest_balance_zero','orig_rel_change','dest_rel_change',\n","    'zero_transfer','same_account','log_amount','type'\n","]\n","\n","# Drop unused cols for modelling stage (keep original df intact)\n","df_model = df.copy()\n","# ensure target exists and is correct dtype\n","df_model['isFraud'] = df_model['isFraud'].astype(int)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tEw9lIgzwsF","executionInfo":{"status":"ok","timestamp":1760263391155,"user_tz":360,"elapsed":27679,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}},"outputId":"03b88f36-2578-4193-84fd-271a993eaf65"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading raw data...\n","Rows, cols: (6362620, 11)\n","Creating engineered features...\n"]}]},{"cell_type":"code","source":["#--------------------\n","# 1) Construct balanced dataset: sample non-fraud 200k and expand fraud via SMOTE to 200k\n","# --------------------\n","print(\"Preparing balanced dataset using sampling + SMOTE...\")\n","\n","# Separate classes\n","df_nonfraud = df_model[df_model['isFraud']==0]\n","df_fraud = df_model[df_model['isFraud']==1]\n","\n","print(\"Original counts:\", df_model['isFraud'].value_counts().to_dict())\n","print(\"Non-fraud total available:\", len(df_nonfraud))\n","print(\"Fraud total available:\", len(df_fraud))\n","\n","# Sample non-fraud\n","if len(df_nonfraud) < NONFRAUD_SAMPLE_N:\n","    raise ValueError(f\"Not enough non-fraud rows to sample {NONFRAUD_SAMPLE_N}\")\n","nonfraud_sample = df_nonfraud.sample(n=NONFRAUD_SAMPLE_N, random_state=RANDOM_STATE).reset_index(drop=True)\n","fraud_df = df_fraud.reset_index(drop=True)  # all fraud rows (8213 expected)\n","\n","print(\"Sampled non-fraud:\", len(nonfraud_sample), \"fraud rows:\", len(fraud_df))\n","\n","# Combine for preprocessor fitting & SMOTE\n","temp = pd.concat([nonfraud_sample, fraud_df], axis=0).reset_index(drop=True)\n","X_temp = temp[feature_cols].copy()\n","y_temp = temp['isFraud'].copy()\n","\n","# Build preprocessor (same as training pipeline)\n","num_cols = [c for c in feature_cols if c != 'type']\n","cat_cols = ['type']\n","\n","numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n","categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))])\n","\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', numeric_transformer, num_cols),\n","    ('cat', categorical_transformer, cat_cols)\n","], remainder='drop')\n","\n","print(\"Fitting preprocessor on combined sample (non-fraud sample + fraud rows)...\")\n","preprocessor.fit(X_temp)\n","\n","print(\"Transforming temp data to numeric matrix for SMOTE...\")\n","X_temp_enc = preprocessor.transform(X_temp)\n","\n","# Now apply SMOTE to expand minority class to FRAUD_TARGET_N\n","print(f\"Running SMOTE to make fraud class = {FRAUD_TARGET_N}...\")\n","sm = SMOTE(sampling_strategy={1: FRAUD_TARGET_N}, random_state=RANDOM_STATE)\n","X_res, y_res = sm.fit_resample(X_temp_enc, y_temp)\n","\n","print(\"After SMOTE sizes: total:\", X_res.shape[0], \"fraud count:\", int((y_res==1).sum()), \"non-fraud count:\", int((y_res==0).sum()))\n","\n","# Reconstruct DataFrame of encoded features for modeling (we only need arrays for model training)\n","# We'll keep X_res (numpy) and y_res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pTwuSQFz5H-","executionInfo":{"status":"ok","timestamp":1760263393554,"user_tz":360,"elapsed":2393,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}},"outputId":"660c5b05-00f9-4012-e3e9-e731ca026d7a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing balanced dataset using sampling + SMOTE...\n","Original counts: {0: 6354407, 1: 8213}\n","Non-fraud total available: 6354407\n","Fraud total available: 8213\n","Sampled non-fraud: 200000 fraud rows: 8213\n","Fitting preprocessor on combined sample (non-fraud sample + fraud rows)...\n","Transforming temp data to numeric matrix for SMOTE...\n","Running SMOTE to make fraud class = 200000...\n","After SMOTE sizes: total: 400000 fraud count: 200000 non-fraud count: 200000\n"]}]},{"cell_type":"code","source":["# --------------------\n","# 2) Train/test split (70/30)\n","# --------------------\n","print(\"Splitting into train/test (70/30)...\")\n","X_train_enc, X_test_enc, y_train, y_test = train_test_split(\n","    X_res, y_res, test_size=TEST_SIZE, stratify=y_res, random_state=RANDOM_STATE\n",")\n","\n","print(\"Train shapes:\", X_train_enc.shape, y_train.shape, \"Test shapes:\", X_test_enc.shape, y_test.shape)\n","\n","# free memory\n","del X_temp, y_temp, X_temp_enc, X_res, y_res, temp, nonfraud_sample, df_nonfraud, df_fraud\n","gc.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sFUWfIV0Isr","executionInfo":{"status":"ok","timestamp":1760263394194,"user_tz":360,"elapsed":634,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}},"outputId":"a6bdbb0c-22d5-44d7-9644-487e405255d1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Splitting into train/test (70/30)...\n","Train shapes: (280000, 18) (280000,) Test shapes: (120000, 18) (120000,)\n"]},{"output_type":"execute_result","data":{"text/plain":["10592"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# --------------------\n","# 3) Setup incremental models & resume logic\n","# --------------------\n","progress = load_progress()\n","start_epoch = progress.get('last_epoch', 0)\n","model_progress = progress.get('models', {})  # track per-model epoch completed\n","\n","# Prepare objects to hold current models/boosters\n","rf_model = None\n","xgb_booster = None\n","lgb_booster = None\n","\n","# If prior checkpoints exist for a model, load latest per model\n","def latest_checkpoint_for(model_name):\n","    files = sorted([f for f in os.listdir(CHECKPOINT_DIR) if f.startswith(model_name+\"_epoch_\")])\n","    return os.path.join(CHECKPOINT_DIR, files[-1]) if files else None\n","\n","# If resuming, try to load last checkpoint per model\n","if start_epoch > 0:\n","    if 'rf' in MODELS_TO_RUN:\n","        ck = latest_checkpoint_for(\"rf\")\n","        if ck:\n","            print(\"Loading RF checkpoint:\", ck)\n","            rf_model = joblib.load(ck)\n","            model_progress['rf'] = int(ck.split(\"_epoch_\")[1].split(\".pkl\")[0])\n","    if 'xgb' in MODELS_TO_RUN:\n","        ck = latest_checkpoint_for(\"xgb\")\n","        if ck:\n","            print(\"Loading XGB checkpoint:\", ck)\n","            xgb_booster = xgb.Booster()\n","            xgb_booster.load_model(ck)\n","            model_progress['xgb'] = int(ck.split(\"_epoch_\")[1].split(\".model\")[0])\n","    if 'lgb' in MODELS_TO_RUN:\n","        ck = latest_checkpoint_for(\"lgb\")\n","        if ck:\n","            print(\"Loading LGB checkpoint:\", ck)\n","            lgb_booster = lgb.Booster(model_file=ck)\n","            model_progress['lgb'] = int(ck.split(\"_epoch_\")[1].split(\".txt\")[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3lf2qfa0ynC","executionInfo":{"status":"ok","timestamp":1760263394207,"user_tz":360,"elapsed":15,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}},"outputId":"3f797adb-519d-4d7e-cb62-57f989a1dbf9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading RF checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_1.pkl\n","Loading XGB checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/xgb_epoch_1.model\n"]}]},{"cell_type":"code","source":["# === FIXED TRAINING LOOP (resumable, stable, no verbosity errors, correct vars) ===\n","import datetime, gc, os, time, joblib\n","from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n","import xgboost as xgb\n","import lightgbm as lgb\n","\n","print(\"\\nðŸš€ Starting training loop (resumable)...\\n\")\n","\n","# âœ… Use encoded variables from previous cell\n","X_train_t = X_train_enc\n","X_test_t  = X_test_enc\n","\n","# === Initialize models ===\n","rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n","xgb_model = None\n","lgb_booster = None\n","\n","# === Define XGBoost and LightGBM parameters ===\n","xgb_params = {\n","    \"objective\": \"binary:logistic\",\n","    \"eval_metric\": \"aucpr\",\n","    \"tree_method\": \"hist\",\n","    \"learning_rate\": 0.1,\n","    \"max_depth\": 6,\n","    \"subsample\": 0.8,\n","    \"colsample_bytree\": 0.8,\n","    \"random_state\": RANDOM_STATE\n","}\n","\n","lgb_params = {\n","    \"objective\": \"binary\",\n","    \"metric\": [\"auc\", \"average_precision\"],\n","    \"learning_rate\": 0.1,\n","    \"num_leaves\": 31,\n","    \"feature_fraction\": 0.8,\n","    \"bagging_fraction\": 0.8,\n","    \"bagging_freq\": 5,\n","    \"seed\": RANDOM_STATE\n","}\n","\n","for epoch in range(1, EPOCHS + 1):\n","    print(f\"\\n=== EPOCH {epoch}/{EPOCHS} ===  {datetime.datetime.now().isoformat()}\")\n","    try:\n","        # === RANDOM FOREST ===\n","        rf.set_params(n_estimators=epoch * RF_TREES_PER_EPOCH)\n","        rf.fit(X_train_t, y_train)\n","        y_pred = rf.predict(X_test_t)\n","        y_proba = rf.predict_proba(X_test_t)[:, 1]\n","\n","        print(f\"\\n[RF] Classification report (threshold=0.5):\")\n","        print(classification_report(y_test, y_pred, digits=4))\n","        print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_proba), 6))\n","        print(\"PR-AUC:\", round(average_precision_score(y_test, y_proba), 6))\n","\n","        rf_path = os.path.join(CHECKPOINT_DIR, f\"rf_epoch_{epoch}.pkl\")\n","        joblib.dump(rf, rf_path)\n","        print(f\"[RF] âœ… Saved checkpoint: {rf_path}\")\n","\n","        # === XGBOOST ===\n","        dtrain = xgb.DMatrix(X_train_t, label=y_train)\n","        dtest = xgb.DMatrix(X_test_t, label=y_test)\n","\n","        print(f\"[XGB] Training +{XGB_ROUNDS_PER_EPOCH} rounds (resume={xgb_model is not None})\")\n","        xgb_model = xgb.train(\n","            xgb_params,\n","            dtrain,\n","            num_boost_round=epoch * XGB_ROUNDS_PER_EPOCH,\n","            xgb_model=xgb_model\n","        )\n","        preds = xgb_model.predict(dtest)\n","        y_pred = (preds >= 0.5).astype(int)\n","\n","        print(f\"[XGB] Classification report (threshold=0.5):\")\n","        print(classification_report(y_test, y_pred, digits=4))\n","        print(\"ROC-AUC:\", round(roc_auc_score(y_test, preds), 6))\n","        print(\"PR-AUC:\", round(average_precision_score(y_test, preds), 6))\n","\n","        xgb_model.save_model(os.path.join(CHECKPOINT_DIR, f\"xgb_epoch_{epoch}.model\"))\n","        print(f\"[XGB] âœ… Saved checkpoint: xgb_epoch_{epoch}.model\")\n","\n","        # === LIGHTGBM ===\n","        lgb_train = lgb.Dataset(X_train_t, label=y_train)\n","        lgb_eval = lgb.Dataset(X_test_t, label=y_test, reference=lgb_train)\n","\n","        print(f\"[LGB] Training +{LGB_ROUNDS_PER_EPOCH} rounds (resume={lgb_booster is not None})\")\n","        lgb_booster = lgb.train(\n","            lgb_params,\n","            lgb_train,\n","            valid_sets=[lgb_train, lgb_eval],\n","            num_boost_round=epoch * LGB_ROUNDS_PER_EPOCH,\n","            init_model=lgb_booster,\n","            callbacks=[\n","                lgb.early_stopping(stopping_rounds=20),\n","                lgb.log_evaluation(period=50)\n","            ]\n","        )\n","        preds = lgb_booster.predict(X_test_t)\n","        y_pred = (preds >= 0.5).astype(int)\n","\n","        print(f\"[LGB] Classification report (threshold=0.5):\")\n","        print(classification_report(y_test, y_pred, digits=4))\n","        print(\"ROC-AUC:\", round(roc_auc_score(y_test, preds), 6))\n","        print(\"PR-AUC:\", round(average_precision_score(y_test, preds), 6))\n","\n","        lgb_path = os.path.join(CHECKPOINT_DIR, f\"lgb_epoch_{epoch}.txt\")\n","        lgb_booster.save_model(lgb_path)\n","        print(f\"[LGB] âœ… Saved checkpoint: {lgb_path}\")\n","\n","    except Exception as e:\n","        print(f\"âš ï¸ Error in epoch {epoch}: {e}\")\n","        continue\n","\n","    gc.collect()\n","    time.sleep(1)\n","\n","print(\"\\nâœ… Training Complete. Checkpoints saved for all epochs.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZYY0SMk06pY","executionInfo":{"status":"ok","timestamp":1760270250422,"user_tz":360,"elapsed":6490978,"user":{"displayName":"Pratham Shah","userId":"11003296118128851860"}},"outputId":"6643ee25-c176-4f7c-eb0e-9076e06220cc"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸš€ Starting training loop (resumable)...\n","\n","\n","=== EPOCH 1/50 ===  2025-10-12T10:09:19.495498\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9985    0.9977    0.9981     60000\n","           1     0.9977    0.9985    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999324\n","PR-AUC: 0.998952\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_1.pkl\n","[XGB] Training +6 rounds (resume=False)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9972    0.9817    0.9894     60000\n","           1     0.9819    0.9972    0.9895     60000\n","\n","    accuracy                         0.9894    120000\n","   macro avg     0.9896    0.9894    0.9894    120000\n","weighted avg     0.9896    0.9894    0.9894    120000\n","\n","ROC-AUC: 0.998529\n","PR-AUC: 0.998195\n","[XGB] âœ… Saved checkpoint: xgb_epoch_1.model\n","[LGB] Training +6 rounds (resume=False)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023070 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","Training until validation scores don't improve for 20 rounds\n","Did not meet early stopping. Best iteration is:\n","[6]\ttraining's auc: 0.998063\ttraining's average_precision: 0.996606\tvalid_1's auc: 0.998179\tvalid_1's average_precision: 0.996885\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9976    0.9898    0.9937     60000\n","           1     0.9899    0.9977    0.9937     60000\n","\n","    accuracy                         0.9937    120000\n","   macro avg     0.9937    0.9937    0.9937    120000\n","weighted avg     0.9937    0.9937    0.9937    120000\n","\n","ROC-AUC: 0.998179\n","PR-AUC: 0.996885\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_1.txt\n","\n","=== EPOCH 2/50 ===  2025-10-12T10:09:28.825381\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999497\n","PR-AUC: 0.999225\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_2.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9981    0.9883    0.9932     60000\n","           1     0.9884    0.9981    0.9932     60000\n","\n","    accuracy                         0.9932    120000\n","   macro avg     0.9932    0.9932    0.9932    120000\n","weighted avg     0.9932    0.9932    0.9932    120000\n","\n","ROC-AUC: 0.999195\n","PR-AUC: 0.99897\n","[XGB] âœ… Saved checkpoint: xgb_epoch_2.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052822 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Did not meet early stopping. Best iteration is:\n","[18]\ttraining's auc: 0.999202\ttraining's average_precision: 0.998925\tvalid_1's auc: 0.99923\tvalid_1's average_precision: 0.998913\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9982    0.9914    0.9948     60000\n","           1     0.9914    0.9982    0.9948     60000\n","\n","    accuracy                         0.9948    120000\n","   macro avg     0.9948    0.9948    0.9948    120000\n","weighted avg     0.9948    0.9948    0.9948    120000\n","\n","ROC-AUC: 0.99923\n","PR-AUC: 0.998913\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_2.txt\n","\n","=== EPOCH 3/50 ===  2025-10-12T10:09:40.674756\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999535\n","PR-AUC: 0.999298\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_3.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9978    0.9900    0.9939     60000\n","           1     0.9901    0.9978    0.9939     60000\n","\n","    accuracy                         0.9939    120000\n","   macro avg     0.9939    0.9939    0.9939    120000\n","weighted avg     0.9939    0.9939    0.9939    120000\n","\n","ROC-AUC: 0.999576\n","PR-AUC: 0.999577\n","[XGB] âœ… Saved checkpoint: xgb_epoch_3.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059484 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Did not meet early stopping. Best iteration is:\n","[36]\ttraining's auc: 0.999693\ttraining's average_precision: 0.999677\tvalid_1's auc: 0.999717\tvalid_1's average_precision: 0.999712\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9985    0.9930    0.9958     60000\n","           1     0.9931    0.9986    0.9958     60000\n","\n","    accuracy                         0.9958    120000\n","   macro avg     0.9958    0.9958    0.9958    120000\n","weighted avg     0.9958    0.9958    0.9958    120000\n","\n","ROC-AUC: 0.999717\n","PR-AUC: 0.999712\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_3.txt\n","\n","=== EPOCH 4/50 ===  2025-10-12T10:09:56.503812\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999591\n","PR-AUC: 0.999386\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_4.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9984    0.9926    0.9955     60000\n","           1     0.9927    0.9984    0.9955     60000\n","\n","    accuracy                         0.9955    120000\n","   macro avg     0.9955    0.9955    0.9955    120000\n","weighted avg     0.9955    0.9955    0.9955    120000\n","\n","ROC-AUC: 0.9997\n","PR-AUC: 0.999703\n","[XGB] âœ… Saved checkpoint: xgb_epoch_4.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023146 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[50]\ttraining's auc: 0.999793\ttraining's average_precision: 0.999785\tvalid_1's auc: 0.999777\tvalid_1's average_precision: 0.999773\n","Did not meet early stopping. Best iteration is:\n","[60]\ttraining's auc: 0.999858\ttraining's average_precision: 0.999851\tvalid_1's auc: 0.99983\tvalid_1's average_precision: 0.999826\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9948    0.9969     60000\n","           1     0.9948    0.9990    0.9969     60000\n","\n","    accuracy                         0.9969    120000\n","   macro avg     0.9969    0.9969    0.9969    120000\n","weighted avg     0.9969    0.9969    0.9969    120000\n","\n","ROC-AUC: 0.99983\n","PR-AUC: 0.999826\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_4.txt\n","\n","=== EPOCH 5/50 ===  2025-10-12T10:10:15.672600\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999614\n","PR-AUC: 0.999434\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_5.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9986    0.9939    0.9962     60000\n","           1     0.9939    0.9986    0.9962     60000\n","\n","    accuracy                         0.9962    120000\n","   macro avg     0.9962    0.9962    0.9962    120000\n","weighted avg     0.9962    0.9962    0.9962    120000\n","\n","ROC-AUC: 0.999778\n","PR-AUC: 0.99978\n","[XGB] âœ… Saved checkpoint: xgb_epoch_5.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029374 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Did not meet early stopping. Best iteration is:\n","[90]\ttraining's auc: 0.999926\ttraining's average_precision: 0.999922\tvalid_1's auc: 0.999875\tvalid_1's average_precision: 0.999873\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9956    0.9973     60000\n","           1     0.9956    0.9991    0.9973     60000\n","\n","    accuracy                         0.9973    120000\n","   macro avg     0.9973    0.9973    0.9973    120000\n","weighted avg     0.9973    0.9973    0.9973    120000\n","\n","ROC-AUC: 0.999875\n","PR-AUC: 0.999873\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_5.txt\n","\n","=== EPOCH 6/50 ===  2025-10-12T10:10:42.616320\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999638\n","PR-AUC: 0.999475\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_6.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9987    0.9953    0.9970     60000\n","           1     0.9953    0.9987    0.9970     60000\n","\n","    accuracy                         0.9970    120000\n","   macro avg     0.9970    0.9970    0.9970    120000\n","weighted avg     0.9970    0.9970    0.9970    120000\n","\n","ROC-AUC: 0.999829\n","PR-AUC: 0.999829\n","[XGB] âœ… Saved checkpoint: xgb_epoch_6.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024072 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[100]\ttraining's auc: 0.999939\ttraining's average_precision: 0.999935\tvalid_1's auc: 0.999879\tvalid_1's average_precision: 0.999877\n","Did not meet early stopping. Best iteration is:\n","[124]\ttraining's auc: 0.999962\ttraining's average_precision: 0.99996\tvalid_1's auc: 0.999897\tvalid_1's average_precision: 0.999894\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9993    0.9965    0.9979     60000\n","           1     0.9965    0.9993    0.9979     60000\n","\n","    accuracy                         0.9979    120000\n","   macro avg     0.9979    0.9979    0.9979    120000\n","weighted avg     0.9979    0.9979    0.9979    120000\n","\n","ROC-AUC: 0.999897\n","PR-AUC: 0.999894\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_6.txt\n","\n","=== EPOCH 7/50 ===  2025-10-12T10:11:13.755884\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999661\n","PR-AUC: 0.999507\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_7.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9987    0.9960    0.9974     60000\n","           1     0.9960    0.9987    0.9974     60000\n","\n","    accuracy                         0.9974    120000\n","   macro avg     0.9974    0.9974    0.9974    120000\n","weighted avg     0.9974    0.9974    0.9974    120000\n","\n","ROC-AUC: 0.999858\n","PR-AUC: 0.999857\n","[XGB] âœ… Saved checkpoint: xgb_epoch_7.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022617 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[150]\ttraining's auc: 0.999976\ttraining's average_precision: 0.999975\tvalid_1's auc: 0.999906\tvalid_1's average_precision: 0.999904\n","Did not meet early stopping. Best iteration is:\n","[160]\ttraining's auc: 0.999979\ttraining's average_precision: 0.999978\tvalid_1's auc: 0.999909\tvalid_1's average_precision: 0.999908\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9992    0.9971    0.9982     60000\n","           1     0.9971    0.9992    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999909\n","PR-AUC: 0.999908\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_7.txt\n","\n","=== EPOCH 8/50 ===  2025-10-12T10:11:51.067120\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999702\n","PR-AUC: 0.999573\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_8.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9987    0.9964    0.9976     60000\n","           1     0.9965    0.9988    0.9976     60000\n","\n","    accuracy                         0.9976    120000\n","   macro avg     0.9976    0.9976    0.9976    120000\n","weighted avg     0.9976    0.9976    0.9976    120000\n","\n","ROC-AUC: 0.999871\n","PR-AUC: 0.999868\n","[XGB] âœ… Saved checkpoint: xgb_epoch_8.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022514 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[200]\ttraining's auc: 0.999994\ttraining's average_precision: 0.999994\tvalid_1's auc: 0.999912\tvalid_1's average_precision: 0.99991\n","Did not meet early stopping. Best iteration is:\n","[208]\ttraining's auc: 0.999994\ttraining's average_precision: 0.999994\tvalid_1's auc: 0.999914\tvalid_1's average_precision: 0.999913\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9974    0.9984     60000\n","           1     0.9975    0.9994    0.9984     60000\n","\n","    accuracy                         0.9984    120000\n","   macro avg     0.9984    0.9984    0.9984    120000\n","weighted avg     0.9984    0.9984    0.9984    120000\n","\n","ROC-AUC: 0.999914\n","PR-AUC: 0.999913\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_8.txt\n","\n","=== EPOCH 9/50 ===  2025-10-12T10:12:33.999947\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999726\n","PR-AUC: 0.999622\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_9.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9968    0.9978     60000\n","           1     0.9968    0.9988    0.9978     60000\n","\n","    accuracy                         0.9978    120000\n","   macro avg     0.9978    0.9978    0.9978    120000\n","weighted avg     0.9978    0.9978    0.9978    120000\n","\n","ROC-AUC: 0.999883\n","PR-AUC: 0.99988\n","[XGB] âœ… Saved checkpoint: xgb_epoch_9.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091796 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[211]\ttraining's auc: 0.999995\ttraining's average_precision: 0.999994\tvalid_1's auc: 0.999915\tvalid_1's average_precision: 0.999914\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9975    0.9984     60000\n","           1     0.9975    0.9994    0.9984     60000\n","\n","    accuracy                         0.9984    120000\n","   macro avg     0.9984    0.9984    0.9984    120000\n","weighted avg     0.9984    0.9984    0.9984    120000\n","\n","ROC-AUC: 0.999915\n","PR-AUC: 0.999914\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_9.txt\n","\n","=== EPOCH 10/50 ===  2025-10-12T10:13:20.953504\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9988    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999733\n","PR-AUC: 0.999629\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_10.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9970    0.9979     60000\n","           1     0.9970    0.9989    0.9979     60000\n","\n","    accuracy                         0.9979    120000\n","   macro avg     0.9979    0.9979    0.9979    120000\n","weighted avg     0.9979    0.9979    0.9979    120000\n","\n","ROC-AUC: 0.999883\n","PR-AUC: 0.999879\n","[XGB] âœ… Saved checkpoint: xgb_epoch_10.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023014 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[217]\ttraining's auc: 0.999995\ttraining's average_precision: 0.999995\tvalid_1's auc: 0.999916\tvalid_1's average_precision: 0.999915\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9975    0.9984     60000\n","           1     0.9975    0.9994    0.9984     60000\n","\n","    accuracy                         0.9984    120000\n","   macro avg     0.9984    0.9984    0.9984    120000\n","weighted avg     0.9984    0.9984    0.9984    120000\n","\n","ROC-AUC: 0.999916\n","PR-AUC: 0.999915\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_10.txt\n","\n","=== EPOCH 11/50 ===  2025-10-12T10:14:09.493723\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999748\n","PR-AUC: 0.999662\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_11.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9972    0.9980     60000\n","           1     0.9972    0.9989    0.9981     60000\n","\n","    accuracy                         0.9980    120000\n","   macro avg     0.9981    0.9980    0.9980    120000\n","weighted avg     0.9981    0.9980    0.9980    120000\n","\n","ROC-AUC: 0.999887\n","PR-AUC: 0.999882\n","[XGB] âœ… Saved checkpoint: xgb_epoch_11.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075886 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[250]\ttraining's auc: 0.999998\ttraining's average_precision: 0.999998\tvalid_1's auc: 0.999919\tvalid_1's average_precision: 0.999918\n","Early stopping, best iteration is:\n","[248]\ttraining's auc: 0.999998\ttraining's average_precision: 0.999998\tvalid_1's auc: 0.999919\tvalid_1's average_precision: 0.999919\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9975    0.9985     60000\n","           1     0.9975    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999919\n","PR-AUC: 0.999919\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_11.txt\n","\n","=== EPOCH 12/50 ===  2025-10-12T10:15:06.655308\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999764\n","PR-AUC: 0.999676\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_12.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9973    0.9981     60000\n","           1     0.9973    0.9990    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999887\n","PR-AUC: 0.999882\n","[XGB] âœ… Saved checkpoint: xgb_epoch_12.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022760 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[250]\ttraining's auc: 0.999998\ttraining's average_precision: 0.999998\tvalid_1's auc: 0.999919\tvalid_1's average_precision: 0.999918\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.99992\tvalid_1's average_precision: 0.999919\n","Early stopping, best iteration is:\n","[280]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999921\tvalid_1's average_precision: 0.99992\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999921\n","PR-AUC: 0.99992\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_12.txt\n","\n","=== EPOCH 13/50 ===  2025-10-12T10:16:09.238564\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999763\n","PR-AUC: 0.999675\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_13.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9974    0.9982     60000\n","           1     0.9974    0.9990    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999886\n","PR-AUC: 0.999881\n","[XGB] âœ… Saved checkpoint: xgb_epoch_13.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022283 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.99992\tvalid_1's average_precision: 0.999919\n","Early stopping, best iteration is:\n","[284]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999921\tvalid_1's average_precision: 0.99992\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999921\n","PR-AUC: 0.99992\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_13.txt\n","\n","=== EPOCH 14/50 ===  2025-10-12T10:17:13.035601\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999763\n","PR-AUC: 0.999676\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_14.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9974    0.9982     60000\n","           1     0.9974    0.9990    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999887\n","PR-AUC: 0.999882\n","[XGB] âœ… Saved checkpoint: xgb_epoch_14.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029876 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.99992\tvalid_1's average_precision: 0.999918\n","Early stopping, best iteration is:\n","[289]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999922\tvalid_1's average_precision: 0.999921\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999922\n","PR-AUC: 0.999921\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_14.txt\n","\n","=== EPOCH 15/50 ===  2025-10-12T10:18:18.749893\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999771\n","PR-AUC: 0.999683\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_15.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9973    0.9982     60000\n","           1     0.9974    0.9990    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999887\n","PR-AUC: 0.999881\n","[XGB] âœ… Saved checkpoint: xgb_epoch_15.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022684 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.99992\tvalid_1's average_precision: 0.999919\n","Early stopping, best iteration is:\n","[292]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_15.txt\n","\n","=== EPOCH 16/50 ===  2025-10-12T10:19:29.061005\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999779\n","PR-AUC: 0.9997\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_16.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9975    0.9982     60000\n","           1     0.9975    0.9990    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999886\n","PR-AUC: 0.99988\n","[XGB] âœ… Saved checkpoint: xgb_epoch_16.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022435 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999921\tvalid_1's average_precision: 0.99992\n","Early stopping, best iteration is:\n","[295]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9985    120000\n","weighted avg     0.9986    0.9986    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_16.txt\n","\n","=== EPOCH 17/50 ===  2025-10-12T10:20:44.966625\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9976    0.9983     60000\n","           1     0.9976    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999786\n","PR-AUC: 0.999716\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_17.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9974    0.9982     60000\n","           1     0.9975    0.9990    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9982    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999886\n","PR-AUC: 0.99988\n","[XGB] âœ… Saved checkpoint: xgb_epoch_17.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069200 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[300]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[302]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_17.txt\n","\n","=== EPOCH 18/50 ===  2025-10-12T10:22:05.773446\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999785\n","PR-AUC: 0.999716\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_18.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9975    0.9982     60000\n","           1     0.9975    0.9990    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9982    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999885\n","PR-AUC: 0.999879\n","[XGB] âœ… Saved checkpoint: xgb_epoch_18.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022504 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[308]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_18.txt\n","\n","=== EPOCH 19/50 ===  2025-10-12T10:23:32.956890\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999803\n","PR-AUC: 0.999752\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_19.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9975    0.9983     60000\n","           1     0.9975    0.9991    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999886\n","PR-AUC: 0.99988\n","[XGB] âœ… Saved checkpoint: xgb_epoch_19.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051595 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[309]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_19.txt\n","\n","=== EPOCH 20/50 ===  2025-10-12T10:25:03.621818\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999811\n","PR-AUC: 0.999768\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_20.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9975    0.9983     60000\n","           1     0.9975    0.9991    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999883\n","PR-AUC: 0.999876\n","[XGB] âœ… Saved checkpoint: xgb_epoch_20.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022433 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[312]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_20.txt\n","\n","=== EPOCH 21/50 ===  2025-10-12T10:26:41.399464\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999818\n","PR-AUC: 0.999785\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_21.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9975    0.9983     60000\n","           1     0.9975    0.9991    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999883\n","PR-AUC: 0.999877\n","[XGB] âœ… Saved checkpoint: xgb_epoch_21.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022469 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[313]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_21.txt\n","\n","=== EPOCH 22/50 ===  2025-10-12T10:28:21.963495\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999826\n","PR-AUC: 0.999792\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_22.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9974    0.9982     60000\n","           1     0.9974    0.9990    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999881\n","PR-AUC: 0.999874\n","[XGB] âœ… Saved checkpoint: xgb_epoch_22.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049215 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[314]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_22.txt\n","\n","=== EPOCH 23/50 ===  2025-10-12T10:30:07.506186\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999826\n","PR-AUC: 0.999793\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_23.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9974    0.9983     60000\n","           1     0.9975    0.9991    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.99988\n","PR-AUC: 0.999872\n","[XGB] âœ… Saved checkpoint: xgb_epoch_23.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023190 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[317]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_23.txt\n","\n","=== EPOCH 24/50 ===  2025-10-12T10:31:57.584549\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999834\n","PR-AUC: 0.9998\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_24.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9974    0.9983     60000\n","           1     0.9974    0.9991    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999879\n","PR-AUC: 0.999871\n","[XGB] âœ… Saved checkpoint: xgb_epoch_24.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022644 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[318]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9985     60000\n","           1     0.9977    0.9994    0.9985     60000\n","\n","    accuracy                         0.9985    120000\n","   macro avg     0.9985    0.9985    0.9985    120000\n","weighted avg     0.9985    0.9985    0.9985    120000\n","\n","ROC-AUC: 0.999923\n","PR-AUC: 0.999922\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_24.txt\n","\n","=== EPOCH 25/50 ===  2025-10-12T10:33:52.173889\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999834\n","PR-AUC: 0.999799\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_25.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9992    0.9973    0.9983     60000\n","           1     0.9974    0.9992    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999877\n","PR-AUC: 0.999868\n","[XGB] âœ… Saved checkpoint: xgb_epoch_25.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022679 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[350]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[335]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999924\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_25.txt\n","\n","=== EPOCH 26/50 ===  2025-10-12T10:35:53.735815\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999834\n","PR-AUC: 0.9998\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_26.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9973    0.9982     60000\n","           1     0.9973    0.9991    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999874\n","PR-AUC: 0.999865\n","[XGB] âœ… Saved checkpoint: xgb_epoch_26.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022612 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999921\n","Early stopping, best iteration is:\n","[340]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999924\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_26.txt\n","\n","=== EPOCH 27/50 ===  2025-10-12T10:37:58.693955\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999833\n","PR-AUC: 0.9998\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_27.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9973    0.9982     60000\n","           1     0.9973    0.9991    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999873\n","PR-AUC: 0.999863\n","[XGB] âœ… Saved checkpoint: xgb_epoch_27.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022967 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[347]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_27.txt\n","\n","=== EPOCH 28/50 ===  2025-10-12T10:40:09.676260\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.999806\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_28.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9973    0.9982     60000\n","           1     0.9973    0.9991    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999872\n","PR-AUC: 0.999862\n","[XGB] âœ… Saved checkpoint: xgb_epoch_28.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022518 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[348]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999924\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_28.txt\n","\n","=== EPOCH 29/50 ===  2025-10-12T10:42:28.266990\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999842\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_29.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9972    0.9981     60000\n","           1     0.9972    0.9991    0.9982     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9982    0.9981    0.9981    120000\n","weighted avg     0.9982    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999871\n","PR-AUC: 0.999861\n","[XGB] âœ… Saved checkpoint: xgb_epoch_29.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022459 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","Early stopping, best iteration is:\n","[349]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_29.txt\n","\n","=== EPOCH 30/50 ===  2025-10-12T10:44:50.676377\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_30.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9972    0.9982     60000\n","           1     0.9972    0.9991    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.99987\n","PR-AUC: 0.999861\n","[XGB] âœ… Saved checkpoint: xgb_epoch_30.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023150 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[350]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_30.txt\n","\n","=== EPOCH 31/50 ===  2025-10-12T10:47:21.704930\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999842\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_31.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9972    0.9981     60000\n","           1     0.9972    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999868\n","PR-AUC: 0.999858\n","[XGB] âœ… Saved checkpoint: xgb_epoch_31.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022523 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[351]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_31.txt\n","\n","=== EPOCH 32/50 ===  2025-10-12T10:49:52.593296\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999842\n","PR-AUC: 0.999809\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_32.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9972    0.9982     60000\n","           1     0.9972    0.9991    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999865\n","PR-AUC: 0.999855\n","[XGB] âœ… Saved checkpoint: xgb_epoch_32.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025735 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[352]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_32.txt\n","\n","=== EPOCH 33/50 ===  2025-10-12T10:52:31.650166\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999842\n","PR-AUC: 0.999809\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_33.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9972    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999863\n","PR-AUC: 0.999852\n","[XGB] âœ… Saved checkpoint: xgb_epoch_33.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084844 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[353]\ttraining's auc: 0.999999\ttraining's average_precision: 0.999999\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_33.txt\n","\n","=== EPOCH 34/50 ===  2025-10-12T10:55:17.711058\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_34.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9971    0.9981     60000\n","           1     0.9971    0.9990    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999862\n","PR-AUC: 0.99985\n","[XGB] âœ… Saved checkpoint: xgb_epoch_34.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022418 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[359]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_34.txt\n","\n","=== EPOCH 35/50 ===  2025-10-12T10:58:06.415488\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_35.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.99986\n","PR-AUC: 0.999848\n","[XGB] âœ… Saved checkpoint: xgb_epoch_35.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022545 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[370]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_35.txt\n","\n","=== EPOCH 36/50 ===  2025-10-12T11:01:00.681048\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.999808\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_36.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9971    0.9981     60000\n","           1     0.9971    0.9990    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999857\n","PR-AUC: 0.999844\n","[XGB] âœ… Saved checkpoint: xgb_epoch_36.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022367 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[373]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_36.txt\n","\n","=== EPOCH 37/50 ===  2025-10-12T11:04:02.382058\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.99985\n","PR-AUC: 0.999826\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_37.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9972    0.9981     60000\n","           1     0.9972    0.9990    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999858\n","PR-AUC: 0.999844\n","[XGB] âœ… Saved checkpoint: xgb_epoch_37.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022580 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[374]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_37.txt\n","\n","=== EPOCH 38/50 ===  2025-10-12T11:07:12.335053\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999857\n","PR-AUC: 0.999832\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_38.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9972    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999855\n","PR-AUC: 0.999842\n","[XGB] âœ… Saved checkpoint: xgb_epoch_38.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022602 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[375]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_38.txt\n","\n","=== EPOCH 39/50 ===  2025-10-12T11:10:23.997346\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999857\n","PR-AUC: 0.999833\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_39.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9972    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999855\n","PR-AUC: 0.999841\n","[XGB] âœ… Saved checkpoint: xgb_epoch_39.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022559 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[377]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_39.txt\n","\n","=== EPOCH 40/50 ===  2025-10-12T11:13:44.119787\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999865\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_40.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999852\n","PR-AUC: 0.999837\n","[XGB] âœ… Saved checkpoint: xgb_epoch_40.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023384 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[378]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_40.txt\n","\n","=== EPOCH 41/50 ===  2025-10-12T11:17:06.017974\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9989    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999864\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_41.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.99985\n","PR-AUC: 0.999834\n","[XGB] âœ… Saved checkpoint: xgb_epoch_41.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061628 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[379]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_41.txt\n","\n","=== EPOCH 42/50 ===  2025-10-12T11:20:42.860168\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999864\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_42.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9970    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999848\n","PR-AUC: 0.999832\n","[XGB] âœ… Saved checkpoint: xgb_epoch_42.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028186 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999921\n","Early stopping, best iteration is:\n","[380]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_42.txt\n","\n","=== EPOCH 43/50 ===  2025-10-12T11:24:17.344871\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9983    0.9983    0.9982    120000\n","weighted avg     0.9983    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999864\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_43.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9971    0.9981     60000\n","           1     0.9971    0.9990    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999847\n","PR-AUC: 0.99983\n","[XGB] âœ… Saved checkpoint: xgb_epoch_43.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077115 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999921\n","Early stopping, best iteration is:\n","[381]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999924\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_43.txt\n","\n","=== EPOCH 44/50 ===  2025-10-12T11:28:05.968344\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9982     60000\n","           1     0.9977    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999864\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_44.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9970    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999847\n","PR-AUC: 0.99983\n","[XGB] âœ… Saved checkpoint: xgb_epoch_44.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022475 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","Early stopping, best iteration is:\n","[382]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9977    0.9986     60000\n","           1     0.9977    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999924\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_44.txt\n","\n","=== EPOCH 45/50 ===  2025-10-12T11:31:55.461914\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9989    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999864\n","PR-AUC: 0.999839\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_45.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999845\n","PR-AUC: 0.999828\n","[XGB] âœ… Saved checkpoint: xgb_epoch_45.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022602 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999922\tvalid_1's average_precision: 0.99992\n","Early stopping, best iteration is:\n","[383]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999923\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999923\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_45.txt\n","\n","=== EPOCH 46/50 ===  2025-10-12T11:35:54.286823\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9976    0.9982     60000\n","           1     0.9976    0.9988    0.9982     60000\n","\n","    accuracy                         0.9982    120000\n","   macro avg     0.9982    0.9982    0.9982    120000\n","weighted avg     0.9982    0.9982    0.9982    120000\n","\n","ROC-AUC: 0.999865\n","PR-AUC: 0.99984\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_46.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9970    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999841\n","PR-AUC: 0.99982\n","[XGB] âœ… Saved checkpoint: xgb_epoch_46.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023253 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999923\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[389]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_46.txt\n","\n","=== EPOCH 47/50 ===  2025-10-12T11:39:55.549680\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999865\n","PR-AUC: 0.99984\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_47.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999842\n","PR-AUC: 0.999821\n","[XGB] âœ… Saved checkpoint: xgb_epoch_47.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073851 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[392]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_47.txt\n","\n","=== EPOCH 48/50 ===  2025-10-12T11:44:01.107608\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999872\n","PR-AUC: 0.999857\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_48.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9990    0.9970    0.9980     60000\n","           1     0.9970    0.9990    0.9980     60000\n","\n","    accuracy                         0.9980    120000\n","   macro avg     0.9980    0.9980    0.9980    120000\n","weighted avg     0.9980    0.9980    0.9980    120000\n","\n","ROC-AUC: 0.99984\n","PR-AUC: 0.999819\n","[XGB] âœ… Saved checkpoint: xgb_epoch_48.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024983 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999924\tvalid_1's average_precision: 0.999922\n","Early stopping, best iteration is:\n","[394]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999925\n","PR-AUC: 0.999924\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_48.txt\n","\n","=== EPOCH 49/50 ===  2025-10-12T11:48:23.218008\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9989    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999872\n","PR-AUC: 0.999857\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_49.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9971    0.9981     60000\n","           1     0.9971    0.9991    0.9981     60000\n","\n","    accuracy                         0.9981    120000\n","   macro avg     0.9981    0.9981    0.9981    120000\n","weighted avg     0.9981    0.9981    0.9981    120000\n","\n","ROC-AUC: 0.999833\n","PR-AUC: 0.999798\n","[XGB] âœ… Saved checkpoint: xgb_epoch_49.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022442 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","[400]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999925\tvalid_1's average_precision: 0.999924\n","Early stopping, best iteration is:\n","[410]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999926\tvalid_1's average_precision: 0.999925\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9995    0.9978    0.9986     60000\n","           1     0.9978    0.9995    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999926\n","PR-AUC: 0.999925\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_49.txt\n","\n","=== EPOCH 50/50 ===  2025-10-12T11:52:47.304035\n","\n","[RF] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9988    0.9977    0.9983     60000\n","           1     0.9977    0.9988    0.9983     60000\n","\n","    accuracy                         0.9983    120000\n","   macro avg     0.9983    0.9983    0.9983    120000\n","weighted avg     0.9983    0.9983    0.9983    120000\n","\n","ROC-AUC: 0.999872\n","PR-AUC: 0.999857\n","[RF] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/rf_epoch_50.pkl\n","[XGB] Training +6 rounds (resume=True)\n","[XGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9991    0.9970    0.9980     60000\n","           1     0.9970    0.9991    0.9981     60000\n","\n","    accuracy                         0.9980    120000\n","   macro avg     0.9981    0.9980    0.9980    120000\n","weighted avg     0.9981    0.9980    0.9980    120000\n","\n","ROC-AUC: 0.99983\n","PR-AUC: 0.999795\n","[XGB] âœ… Saved checkpoint: xgb_epoch_50.model\n","[LGB] Training +6 rounds (resume=True)\n","[LightGBM] [Info] Number of positive: 140000, number of negative: 140000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023172 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2424\n","[LightGBM] [Info] Number of data points in the train set: 280000, number of used features: 17\n","Training until validation scores don't improve for 20 rounds\n","Early stopping, best iteration is:\n","[418]\ttraining's auc: 1\ttraining's average_precision: 1\tvalid_1's auc: 0.999927\tvalid_1's average_precision: 0.999925\n","[LGB] Classification report (threshold=0.5):\n","              precision    recall  f1-score   support\n","\n","           0     0.9994    0.9978    0.9986     60000\n","           1     0.9978    0.9994    0.9986     60000\n","\n","    accuracy                         0.9986    120000\n","   macro avg     0.9986    0.9986    0.9986    120000\n","weighted avg     0.9986    0.9986    0.9986    120000\n","\n","ROC-AUC: 0.999927\n","PR-AUC: 0.999925\n","[LGB] âœ… Saved checkpoint: /content/drive/MyDrive/fraud_detection_checkpoints/epoch_checkpoints/lgb_epoch_50.txt\n","\n","âœ… Training Complete. Checkpoints saved for all epochs.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uTyXElZz0_7Y"},"execution_count":null,"outputs":[]}]}